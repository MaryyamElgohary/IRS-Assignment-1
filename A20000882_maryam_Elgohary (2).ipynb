{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **A20000882_Maryam Elgohary**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aUjzx6b_0d1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Web Scraping dataset**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TSFlVIACus-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import time\n",
        "\n",
        "book_urls = {\n",
        "    \"jane eyre\": \"https://www.goodreads.com/book/show/10210.Jane_Eyre\",\n",
        "    \"1984\": \"https://www.goodreads.com/book/show/61439040-1984\",\n",
        "    'wuthering': 'https://www.goodreads.com/book/show/6185.Wuthering_Heights',\n",
        "    'picture of dorian ': 'https://www.goodreads.com/book/show/5297.The_Picture_of_Dorian_Gray',\n",
        "    'catcher in rye': 'https://www.goodreads.com/book/show/5107.The_Catcher_in_the_Rye',\n",
        "    'sense and sensibility':'https://www.goodreads.com/book/show/14935.Sense_and_Sensibility',\n",
        "    'great expectations':'https://www.goodreads.com/book/show/2623.Great_Expectations',\n",
        "    'tale of cities':'https://www.goodreads.com/book/show/1953.A_Tale_of_Two_Cities',\n",
        "    'brave new world': 'https://www.goodreads.com/book/show/5129.Brave_New_World',\n",
        "    'macbeth':'https://www.goodreads.com/book/show/43913694-macbeth',\n",
        "    \"The Great Gatsby\": \"https://www.goodreads.com/book/show/4671.The_Great_Gatsby\"\n",
        "}\n",
        "\n",
        "book_reviews = {}\n",
        "\n",
        "for book_name, book_url in book_urls.items():\n",
        "    response = requests.get(book_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    users = soup.find_all(\"div\", class_=\"ReviewerProfile__name\")\n",
        "    ratings = soup.find_all(\"span\", class_=\"RatingStars\")\n",
        "\n",
        "\n",
        "    reviews = {}\n",
        "    for i in range(min(len(users), len(ratings))):\n",
        "        user_name = users[i].text.strip()\n",
        "\n",
        "\n",
        "\n",
        "        rating_value = float(rating_text.split()[1]) if \"out of\" in rating_text else None\n",
        "\n",
        "\n",
        "        reviews[user_name] = rating_value\n",
        "\n",
        "\n",
        "    book_reviews[book_name] = reviews\n",
        "\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "\n",
        "book_dfs = [pd.DataFrame.from_dict(book_reviews[book], orient=\"index\", columns=[book]) for book in book_urls.keys()]\n",
        "\n",
        "common_df = book_dfs[0]\n",
        "for df in book_dfs[1:]:\n",
        "    common_df = pd.concat([common_df, df], axis=1)\n",
        "\n",
        "common_df['Review Count'] = common_df.notnull().sum(axis=1)\n",
        "common_users_df = common_df[common_df['Review Count'] >= 5].drop(columns=['Review Count'])\n",
        "\n",
        "\n",
        "print(common_users_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvl48OXhurbY",
        "outputId": "2ea9e6e1-22de-4dd4-8f6e-6f13ce1d2e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         jane eyre  1984  wuthering  picture of dorian   \\\n",
            "Sean Barrs                     0.0  5.00       1.00                4.13   \n",
            "emma                           0.0  5.00       0.00                5.00   \n",
            "Matthew                        5.0  5.00        NaN                 NaN   \n",
            "Lisa of Troy                   5.0   NaN       1.00                4.00   \n",
            "Emily May                      5.0  4.00       3.89                0.00   \n",
            "Nayra.Hassan                   1.0   NaN        NaN                5.00   \n",
            "Anne                           1.0   NaN        NaN                5.00   \n",
            "Ahmad Sharabiani               3.0  4.00       1.00                5.00   \n",
            "Henry Avila                    2.0   NaN       4.00                5.00   \n",
            "هدى يحيى                       NaN  4.19        NaN                5.00   \n",
            "Stephen                        NaN  5.00        NaN                0.00   \n",
            "Luís                           NaN  4.00        NaN                 NaN   \n",
            "Mario the lone bookwolf        NaN  4.00        NaN                5.00   \n",
            "\n",
            "                         catcher in rye  sense and sensibility  \\\n",
            "Sean Barrs                          NaN                   0.00   \n",
            "emma                                2.0                    NaN   \n",
            "Matthew                             NaN                    NaN   \n",
            "Lisa of Troy                        1.0                   3.00   \n",
            "Emily May                           NaN                    NaN   \n",
            "Nayra.Hassan                        NaN                    NaN   \n",
            "Anne                                NaN                   2.00   \n",
            "Ahmad Sharabiani                    1.0                   5.00   \n",
            "Henry Avila                         5.0                   5.00   \n",
            "هدى يحيى                            NaN                    NaN   \n",
            "Stephen                             3.8                   4.09   \n",
            "Luís                                5.0                   5.00   \n",
            "Mario the lone bookwolf             5.0                    NaN   \n",
            "\n",
            "                         great expectations  tale of cities  brave new world  \\\n",
            "Sean Barrs                             3.79            4.00             0.00   \n",
            "emma                                   0.00             NaN             5.00   \n",
            "Matthew                                5.00            5.00              NaN   \n",
            "Lisa of Troy                            NaN             NaN             3.00   \n",
            "Emily May                              0.00             NaN             3.99   \n",
            "Nayra.Hassan                           5.00            3.87              NaN   \n",
            "Anne                                    NaN             NaN             4.00   \n",
            "Ahmad Sharabiani                       4.00            5.00             2.00   \n",
            "Henry Avila                            2.00             NaN              NaN   \n",
            "هدى يحيى                                NaN             NaN             4.00   \n",
            "Stephen                                5.00             NaN             0.00   \n",
            "Luís                                    NaN            5.00             5.00   \n",
            "Mario the lone bookwolf                5.00            0.00             5.00   \n",
            "\n",
            "                         macbeth  The Great Gatsby  \n",
            "Sean Barrs                  5.00              3.93  \n",
            "emma                        5.00              4.00  \n",
            "Matthew                      NaN              3.00  \n",
            "Lisa of Troy                 NaN              0.00  \n",
            "Emily May                   5.00               NaN  \n",
            "Nayra.Hassan                5.00               NaN  \n",
            "Anne                         NaN              5.00  \n",
            "Ahmad Sharabiani            3.89              5.00  \n",
            "Henry Avila                 5.00              5.00  \n",
            "هدى يحيى                    5.00              3.00  \n",
            "Stephen                      NaN              3.00  \n",
            "Luís                        5.00               NaN  \n",
            "Mario the lone bookwolf      NaN               NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling missing data**"
      ],
      "metadata": {
        "id": "E1kJC0Huu9CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_path = '/content/dl33lataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "total_elements = df.iloc[:, 1:].size\n",
        "\n",
        "row_means = df.iloc[:, 1:].mean(axis=1, skipna=True)\n",
        "\n",
        "def fill_row_with_mean(row):\n",
        "    if pd.isna(row).any():\n",
        "        mean_value = row_means[row.name]\n",
        "    return row\n",
        "\n",
        "df.iloc[:, 1:] = df.iloc[:, 1:].apply(fill_row_with_mean, axis=1)\n",
        "\n",
        "num_missing = int(total_elements * 0.1)\n",
        "\n",
        "all_indices = [(i, j) for i in range(df.shape[0]) for j in range(1, df.shape[1])]\n",
        "missing_indices = np.random.choice(range(len(all_indices)), num_missing, replace=False)\n",
        "\n",
        "\n",
        "for index in missing_indices:\n",
        "    row, col = all_indices[index]\n",
        "    df.iat[row, col] = np.nan\n",
        "\n",
        "\n",
        "print(\"DataFrame with Missing Values (NaN):\")\n",
        "print(df)\n",
        "\n",
        "output_file_path = '/content/dl33lataset.xlsx'\n",
        "df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(\"\\nDataFrame with Filled Missing Values:\")\n",
        "print(df)\n",
        ""
      ],
      "metadata": {
        "id": "yRtCwG71Gu5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3073ed55-d2ff-4d33-d018-742bf51c3ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with Missing Values (NaN):\n",
            "                 Unnamed: 0  jane eyre      1984  wuthering  \\\n",
            "0                Sean Barrs   0.000000  5.000000       1.00   \n",
            "1                      emma   0.000000  5.000000       3.20   \n",
            "2                   Matthew   5.000000  5.000000       3.00   \n",
            "3              Lisa of Troy   5.000000  2.000000       1.00   \n",
            "4                 Emily May   5.000000  4.000000       3.89   \n",
            "5              Nayra.Hassan   1.000000  3.333333       3.00   \n",
            "6                      Anne   3.000000  2.000000       3.00   \n",
            "7          Ahmad Sharabiani   3.000000  4.000000       1.00   \n",
            "8               Henry Avila   5.000000  2.000000       4.00   \n",
            "9                  هدى يحيى   3.465556  4.190000       3.00   \n",
            "10                      NaN   2.000000  3.010000       3.00   \n",
            "11                     Luís   2.000000  4.000000       3.00   \n",
            "12  Mario the lone bookwolf   3.700000  4.000000        NaN   \n",
            "\n",
            "    picture of dorian   catcher in rye  sense and sensibility  \\\n",
            "0                 4.13        2.983333               2.983333   \n",
            "1                 5.00             NaN               1.000000   \n",
            "2                 3.00        3.000000               1.000000   \n",
            "3                 4.00        1.000000               3.000000   \n",
            "4                 0.00        3.000000               1.000000   \n",
            "5                 5.00        3.000000               1.000000   \n",
            "6                 5.00        3.000000               5.000000   \n",
            "7                 5.00        3.489000               2.000000   \n",
            "8                 5.00        5.000000               5.000000   \n",
            "9                 5.00        3.000000               1.000000   \n",
            "10                0.00        3.010000                    NaN   \n",
            "11                 NaN        3.800000               5.000000   \n",
            "12                5.00        5.000000               1.000000   \n",
            "\n",
            "    great expectations  tale of cities  brave new world  macbeth  \\\n",
            "0                 3.79        4.000000         0.000000     5.00   \n",
            "1                 0.00        5.000000         5.000000     5.00   \n",
            "2                 5.00        5.000000         3.000000     5.00   \n",
            "3                 2.00        5.000000              NaN     5.00   \n",
            "4                 0.00             NaN         3.990000     5.00   \n",
            "5                 5.00        3.333333         3.000000     5.00   \n",
            "6                 2.00        5.000000         4.000000     5.00   \n",
            "7                 4.00        5.000000         2.000000     3.89   \n",
            "8                 4.40        5.000000         3.000000      NaN   \n",
            "9                 2.00        5.000000         3.465556     5.00   \n",
            "10                5.00        5.000000         0.000000      NaN   \n",
            "11                2.00        5.000000         5.000000      NaN   \n",
            "12                 NaN        0.000000              NaN     5.00   \n",
            "\n",
            "    The Great Gatsby  \n",
            "0              3.930  \n",
            "1                NaN  \n",
            "2              3.000  \n",
            "3              0.000  \n",
            "4              3.088  \n",
            "5                NaN  \n",
            "6              5.000  \n",
            "7                NaN  \n",
            "8              5.000  \n",
            "9              3.000  \n",
            "10             3.000  \n",
            "11             4.000  \n",
            "12             4.000  \n",
            "\n",
            "DataFrame with Filled Missing Values:\n",
            "                 Unnamed: 0  jane eyre      1984  wuthering  \\\n",
            "0                Sean Barrs   0.000000  5.000000       1.00   \n",
            "1                      emma   0.000000  5.000000       3.20   \n",
            "2                   Matthew   5.000000  5.000000       3.00   \n",
            "3              Lisa of Troy   5.000000  2.000000       1.00   \n",
            "4                 Emily May   5.000000  4.000000       3.89   \n",
            "5              Nayra.Hassan   1.000000  3.333333       3.00   \n",
            "6                      Anne   3.000000  2.000000       3.00   \n",
            "7          Ahmad Sharabiani   3.000000  4.000000       1.00   \n",
            "8               Henry Avila   5.000000  2.000000       4.00   \n",
            "9                  هدى يحيى   3.465556  4.190000       3.00   \n",
            "10                      NaN   2.000000  3.010000       3.00   \n",
            "11                     Luís   2.000000  4.000000       3.00   \n",
            "12  Mario the lone bookwolf   3.700000  4.000000        NaN   \n",
            "\n",
            "    picture of dorian   catcher in rye  sense and sensibility  \\\n",
            "0                 4.13        2.983333               2.983333   \n",
            "1                 5.00             NaN               1.000000   \n",
            "2                 3.00        3.000000               1.000000   \n",
            "3                 4.00        1.000000               3.000000   \n",
            "4                 0.00        3.000000               1.000000   \n",
            "5                 5.00        3.000000               1.000000   \n",
            "6                 5.00        3.000000               5.000000   \n",
            "7                 5.00        3.489000               2.000000   \n",
            "8                 5.00        5.000000               5.000000   \n",
            "9                 5.00        3.000000               1.000000   \n",
            "10                0.00        3.010000                    NaN   \n",
            "11                 NaN        3.800000               5.000000   \n",
            "12                5.00        5.000000               1.000000   \n",
            "\n",
            "    great expectations  tale of cities  brave new world  macbeth  \\\n",
            "0                 3.79        4.000000         0.000000     5.00   \n",
            "1                 0.00        5.000000         5.000000     5.00   \n",
            "2                 5.00        5.000000         3.000000     5.00   \n",
            "3                 2.00        5.000000              NaN     5.00   \n",
            "4                 0.00             NaN         3.990000     5.00   \n",
            "5                 5.00        3.333333         3.000000     5.00   \n",
            "6                 2.00        5.000000         4.000000     5.00   \n",
            "7                 4.00        5.000000         2.000000     3.89   \n",
            "8                 4.40        5.000000         3.000000      NaN   \n",
            "9                 2.00        5.000000         3.465556     5.00   \n",
            "10                5.00        5.000000         0.000000      NaN   \n",
            "11                2.00        5.000000         5.000000      NaN   \n",
            "12                 NaN        0.000000              NaN     5.00   \n",
            "\n",
            "    The Great Gatsby  \n",
            "0              3.930  \n",
            "1                NaN  \n",
            "2              3.000  \n",
            "3              0.000  \n",
            "4              3.088  \n",
            "5                NaN  \n",
            "6              5.000  \n",
            "7                NaN  \n",
            "8              5.000  \n",
            "9              3.000  \n",
            "10             3.000  \n",
            "11             4.000  \n",
            "12             4.000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_users_df = pd.read_excel('/content/dl33lataset.xlsx')\n",
        "item_based = common_users_df.transpose()\n",
        "item_based.to_excel('itemBased.xlsx', index=True)"
      ],
      "metadata": {
        "id": "bSEG45ACxZuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **computing Average**"
      ],
      "metadata": {
        "id": "yG2Cv0PMymNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "user_based_df = pd.read_excel('/content/ddataset.xlsx')\n",
        "user_based_df = user_based_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "row_averages = user_based_df.mean(axis=1)\n",
        "\n",
        "for index, avg in enumerate(row_averages):\n",
        "    print(f\"Average rating for User {index + 1}: {avg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHfyEAZGvMeW",
        "outputId": "a5d63d79-467b-422d-95d5-def34eefd173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rating for User 1: 2.34\n",
            "Average rating for User 2: 2.909090909090909\n",
            "Average rating for User 3: 3.8\n",
            "Average rating for User 4: 2.4444444444444446\n",
            "Average rating for User 5: 3.1709090909090913\n",
            "Average rating for User 6: 3.2869999999999995\n",
            "Average rating for User 7: 3.8888888888888884\n",
            "Average rating for User 8: 3.489\n",
            "Average rating for User 9: 4.1000000000000005\n",
            "Average rating for User 10: 3.380909090909091\n",
            "Average rating for User 11: 3.2627272727272727\n",
            "Average rating for User 12: 3.666666666666667\n",
            "Average rating for User 13: 3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cosine Similarity User-based**"
      ],
      "metadata": {
        "id": "_r-k0NlAwNNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "user_based_df = pd.read_excel('/content/ddataset.xlsx')\n",
        "\n",
        "user_based_df = user_based_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "filled_df = user_based_df.fillna(0)\n",
        "\n",
        "target_row = filled_df.iloc[2].values.reshape(1, -1)\n",
        "\n",
        "\n",
        "similarities = cosine_similarity(target_row, filled_df)\n",
        "\n",
        "similarity_df = pd.DataFrame(similarities.flatten(), columns=[\"Cosine Similarity\"])\n",
        "similarity_df['User'] = filled_df.index\n",
        "\n",
        "similarity_df = similarity_df[similarity_df['User'] != filled_df.index[2]]\n",
        "\n",
        "top_similar_users = similarity_df.nlargest(2, \"Cosine Similarity\")\n",
        "\n",
        "null_columns = user_based_df.columns[user_based_df.iloc[2].isnull()]\n",
        "\n",
        "\n",
        "ratings_from_neighbors = user_based_df.loc[top_similar_users['User'].values, null_columns]\n",
        "\n",
        "\n",
        "weights = top_similar_users['Cosine Similarity'].values\n",
        "weighted_ratings = ratings_from_neighbors.T.dot(weights) / weights.sum()\n",
        "\n",
        "\n",
        "user_based_df.loc[3, null_columns] = weighted_ratings\n",
        "\n",
        "\n",
        "print(user_based_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6blmcf5wMXq",
        "outputId": "6fd09070-ee1f-4a2a-d8c9-344daeb048d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    jane eyre      1984  wuthering  picture of dorian   catcher in rye  \\\n",
            "0    0.000000  5.000000      1.000            4.130000        3.000000   \n",
            "1    0.000000  5.000000      0.000            5.000000        2.000000   \n",
            "2    5.000000  5.000000      3.000            3.000000        3.000000   \n",
            "3    2.444444  2.000000      1.000            2.444444        1.000000   \n",
            "4    5.000000  4.000000      3.890            0.000000        3.000000   \n",
            "5    1.000000  2.000000      3.287            5.000000        3.000000   \n",
            "6    3.000000  3.888889      3.000            5.000000        3.000000   \n",
            "7    3.000000  4.000000      3.489            5.000000        1.000000   \n",
            "8    5.000000  2.000000      4.000            5.000000        5.000000   \n",
            "9    2.000000  4.190000      3.000            5.000000        3.000000   \n",
            "10   2.000000  5.000000      3.000            0.000000        3.800000   \n",
            "11   2.000000  4.000000      3.000            3.000000        3.666667   \n",
            "12   2.000000  4.000000      3.000            3.400000        5.000000   \n",
            "\n",
            "    sense and sensibility  great expectations  tale of cities  \\\n",
            "0                    0.00                2.34            4.00   \n",
            "1                    1.00                0.00            5.00   \n",
            "2                    1.00                5.00            5.00   \n",
            "3                    3.00                2.00            5.00   \n",
            "4                    1.00                0.00            5.00   \n",
            "5                    1.00                5.00            3.87   \n",
            "6                    5.00                2.00            5.00   \n",
            "7                    2.00                4.00            5.00   \n",
            "8                    5.00                2.00            5.00   \n",
            "9                    1.00                2.00            5.00   \n",
            "10                   4.09                5.00            5.00   \n",
            "11                   5.00                2.00            5.00   \n",
            "12                   1.00                5.00            0.00   \n",
            "\n",
            "    brave new world   macbeth  The Great Gatsby  \n",
            "0              0.00  2.340000          3.930000  \n",
            "1              5.00  5.000000          4.000000  \n",
            "2              3.80  5.000000          3.000000  \n",
            "3              3.00  5.000000          0.000000  \n",
            "4              3.99  5.000000          4.000000  \n",
            "5              3.00  5.000000          4.000000  \n",
            "6              4.00  5.000000          3.888889  \n",
            "7              2.00  3.890000          5.000000  \n",
            "8              3.00  4.100000          5.000000  \n",
            "9              4.00  5.000000          3.000000  \n",
            "10             0.00  5.000000          3.000000  \n",
            "11             5.00  3.666667          4.000000  \n",
            "12             5.00  5.000000          4.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cosine Similarity item-based**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5JQZhmQZxFRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "item_based_df = pd.read_excel('/content/itemBased.xlsx')\n",
        "\n",
        "\n",
        "item_based_df = item_based_df.drop(columns=[\"Unnamed: 0\"], errors='ignore')\n",
        "\n",
        "\n",
        "for col in item_based_df.columns:\n",
        "    item_based_df[col] = pd.to_numeric(item_based_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "item_based_df = item_based_df.select_dtypes(include=[np.number])\n",
        "\n",
        "if item_based_df.shape[1] == 0:\n",
        "    raise ValueError(\"No numeric columns available for similarity calculation. Please ensure your dataset has numeric rating columns.\")\n",
        "\n",
        "\n",
        "filled_df = item_based_df.fillna(0)\n",
        "\n",
        "if filled_df.shape[1] == 0:\n",
        "    raise ValueError(\"After filling NaN values, there are still no columns available for similarity calculation.\")\n",
        "\n",
        "row_index = 2\n",
        "row_ratings = filled_df.iloc[row_index].values.reshape(1, -1)\n",
        "\n",
        "\n",
        "similarities = cosine_similarity(row_ratings, filled_df)\n",
        "\n",
        "\n",
        "similarity_df = pd.DataFrame(similarities.flatten(), columns=[\"Cosine Similarity\"])\n",
        "similarity_df['item'] = filled_df.index\n",
        "\n",
        "\n",
        "similarity_df = similarity_df[similarity_df['item'] != row_index]\n",
        "\n",
        "top_similar_item = similarity_df.nlargest(2, \"Cosine Similarity\")\n",
        "\n",
        "null_columns = item_based_df.columns[item_based_df.iloc[row_index].isnull()]\n",
        "ratings_from_neighbors = item_based_df.loc[top_similar_item['item'].values, null_columns]\n",
        "\n",
        "\n",
        "weights = top_similar_item['Cosine Similarity'].values\n",
        "weighted_ratings = ratings_from_neighbors.T.dot(weights) / weights.sum()\n",
        "\n",
        "item_based_df.loc[row_index, null_columns] = weighted_ratings\n",
        "\n",
        "\n",
        "print(\"Updated DataFrame:\\n\", item_based_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI3Ki-AHxDNP",
        "outputId": "360e83e0-e235-4846-a080-f23bb290c597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame:\n",
            "        0         1    2         3     4      5         6      7    8     9  \\\n",
            "0   2.34  2.909091  NaN       NaN   NaN    NaN       NaN    NaN  NaN   NaN   \n",
            "1   0.00  0.000000  5.0  2.444444  5.00  1.000  3.000000  3.000  5.0  2.00   \n",
            "2   5.00  5.000000  5.0  2.000000  4.00  2.000  3.888889  4.000  2.0  4.19   \n",
            "3   1.00  0.000000  3.0  1.000000  3.89  3.287  3.000000  3.489  4.0  3.00   \n",
            "4   4.13  5.000000  3.0  2.444444  0.00  5.000  5.000000  5.000  5.0  5.00   \n",
            "5   3.00  2.000000  3.0  1.000000  3.00  3.000  3.000000  1.000  5.0  3.00   \n",
            "6   0.00  1.000000  1.0  3.000000  1.00  1.000  5.000000  2.000  5.0  1.00   \n",
            "7   2.34  0.000000  5.0  2.000000  0.00  5.000  2.000000  4.000  2.0  2.00   \n",
            "8   4.00  5.000000  5.0  5.000000  5.00  3.870  5.000000  5.000  5.0  5.00   \n",
            "9   0.00  5.000000  3.8  3.000000  3.99  3.000  4.000000  2.000  3.0  4.00   \n",
            "10  2.34  5.000000  5.0  5.000000  5.00  5.000  5.000000  3.890  4.1  5.00   \n",
            "11  3.93  4.000000  3.0  0.000000  4.00  4.000  3.888889  5.000  5.0  3.00   \n",
            "\n",
            "      10        11   12  \n",
            "0    NaN       NaN  NaN  \n",
            "1   2.00  2.000000  2.0  \n",
            "2   5.00  4.000000  4.0  \n",
            "3   3.00  3.000000  3.0  \n",
            "4   0.00  3.000000  3.4  \n",
            "5   3.80  3.666667  5.0  \n",
            "6   4.09  5.000000  1.0  \n",
            "7   5.00  2.000000  5.0  \n",
            "8   5.00  5.000000  0.0  \n",
            "9   0.00  5.000000  5.0  \n",
            "10  5.00  3.666667  5.0  \n",
            "11  3.00  4.000000  4.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pearson Correlation User-Based**"
      ],
      "metadata": {
        "id": "sdyX86SRxzfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "user_based_df = pd.read_excel('/content/ddataset.xlsx')\n",
        "user_based_df = user_based_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "target_user_index = 2\n",
        "target_user = user_based_df.iloc[target_user_index]\n",
        "null_columns = user_based_df.columns[target_user.isnull()]\n",
        "\n",
        "\n",
        "user_means = user_based_df.mean(axis=1)\n",
        "\n",
        "\n",
        "def predict_rating(user_index, item):\n",
        "    target_user = user_based_df.iloc[user_index]\n",
        "    target_user_mean = user_means[user_index]\n",
        "\n",
        "\n",
        "    similarities = user_based_df.apply(lambda x: target_user.corr(x), axis=1)\n",
        "    similar_users = similarities.drop(user_index).dropna()\n",
        "    rated_users = user_based_df[~user_based_df[item].isnull()].index\n",
        "    neighbors = similar_users[similar_users.index.isin(rated_users)]\n",
        "    top_neighbors = neighbors.nlargest(2)\n",
        "    numerator = sum(top_neighbors[i] * (user_based_df.loc[i, item] - user_means[i]) for i in top_neighbors.index)\n",
        "    denominator = top_neighbors.sum()\n",
        "\n",
        "    if denominator == 0:\n",
        "        return target_user_mean\n",
        "\n",
        "\n",
        "    prediction = target_user_mean + (numerator / denominator)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "for item in null_columns:\n",
        "    predicted_rating = predict_rating(target_user_index, item)\n",
        "    user_based_df.at[target_user_index, item] = predicted_rating\n",
        "\n",
        "\n",
        "print(user_based_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMqanTY2x62p",
        "outputId": "edca3516-d15c-4247-b826-056c88c4fb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    jane eyre      1984  wuthering  picture of dorian   catcher in rye  \\\n",
            "0    0.000000  5.000000      1.000            4.130000        3.000000   \n",
            "1    0.000000  5.000000      0.000            5.000000        2.000000   \n",
            "2    5.000000  5.000000      3.000            3.000000        3.000000   \n",
            "3    2.444444  2.000000      1.000            2.444444        1.000000   \n",
            "4    5.000000  4.000000      3.890            0.000000        3.000000   \n",
            "5    1.000000  2.000000      3.287            5.000000        3.000000   \n",
            "6    3.000000  3.888889      3.000            5.000000        3.000000   \n",
            "7    3.000000  4.000000      3.489            5.000000        1.000000   \n",
            "8    5.000000  2.000000      4.000            5.000000        5.000000   \n",
            "9    2.000000  4.190000      3.000            5.000000        3.000000   \n",
            "10   2.000000  5.000000      3.000            0.000000        3.800000   \n",
            "11   2.000000  4.000000      3.000            3.000000        3.666667   \n",
            "12   2.000000  4.000000      3.000            3.400000        5.000000   \n",
            "\n",
            "    sense and sensibility  great expectations  tale of cities  \\\n",
            "0                    0.00                2.34            4.00   \n",
            "1                    1.00                0.00            5.00   \n",
            "2                    1.00                5.00            5.00   \n",
            "3                    3.00                2.00            5.00   \n",
            "4                    1.00                0.00            5.00   \n",
            "5                    1.00                5.00            3.87   \n",
            "6                    5.00                2.00            5.00   \n",
            "7                    2.00                4.00            5.00   \n",
            "8                    5.00                2.00            5.00   \n",
            "9                    1.00                2.00            5.00   \n",
            "10                   4.09                5.00            5.00   \n",
            "11                   5.00                2.00            5.00   \n",
            "12                   1.00                5.00            0.00   \n",
            "\n",
            "    brave new world   macbeth  The Great Gatsby  \n",
            "0              0.00  2.340000          3.930000  \n",
            "1              5.00  5.000000          4.000000  \n",
            "2              3.80  5.000000          3.000000  \n",
            "3              3.00  5.000000          0.000000  \n",
            "4              3.99  5.000000          4.000000  \n",
            "5              3.00  5.000000          4.000000  \n",
            "6              4.00  5.000000          3.888889  \n",
            "7              2.00  3.890000          5.000000  \n",
            "8              3.00  4.100000          5.000000  \n",
            "9              4.00  5.000000          3.000000  \n",
            "10             0.00  5.000000          3.000000  \n",
            "11             5.00  3.666667          4.000000  \n",
            "12             5.00  5.000000          4.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pearson correlation User based experimenting the mae**"
      ],
      "metadata": {
        "id": "RKzuvRKmvF6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "user_based_df = pd.read_excel('/content/sdataset.xlsx')\n",
        "user_based_df = user_based_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "\n",
        "def predict_rating(user_index, item, df):\n",
        "    target_user = df.iloc[user_index]\n",
        "    target_user_mean = target_user.mean()\n",
        "\n",
        "    similarities = df.apply(lambda x: target_user.corr(x), axis=1)\n",
        "    similar_users = similarities.drop(user_index).dropna()\n",
        "\n",
        "    rated_users = df[~df[item].isnull()].index\n",
        "    neighbors = similar_users[similar_users.index.isin(rated_users)]\n",
        "\n",
        "    top_neighbors = neighbors.nlargest(2)\n",
        "    numerator = sum(top_neighbors[i] * (df.loc[i, item] - df.mean(axis=1)[i]) for i in top_neighbors.index)\n",
        "    denominator = top_neighbors.sum()\n",
        "\n",
        "    if denominator == 0:\n",
        "        return target_user_mean\n",
        "\n",
        "    prediction = target_user_mean + (numerator / denominator)\n",
        "    return prediction\n",
        "\n",
        "user_index = 5\n",
        "item = 'jane eyre'\n",
        "known_rating = user_based_df.loc[user_index, item]\n",
        "\n",
        "\n",
        "user_based_df.loc[user_index, item] = np.nan\n",
        "\n",
        "predicted_rating = predict_rating(user_index, item, user_based_df)\n",
        "\n",
        "mae = abs(predicted_rating - known_rating)\n",
        "\n",
        "# Display the results\n",
        "print(f'Known Rating: {known_rating}')\n",
        "print(f'Predicted Rating: {predicted_rating}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "\n",
        "# Optionally, reset the original rating back\n",
        "user_based_df.loc[user_index, item] = known_rating\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmGBxxWVuPfS",
        "outputId": "3ac26dc4-cff0-444a-c9fd-d54231a2fb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Known Rating: 1\n",
            "Predicted Rating: 1.4184970876609877\n",
            "Mean Absolute Error (MAE): 0.4184970876609877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **item-based Pearson Correlation**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A0FOxLDAzUXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Load the dataset\n",
        "item_based_df = pd.read_excel('/content/itemBased.xlsx')  # Adjust the file path as needed\n",
        "\n",
        "# Drop the first column if it's an unnecessary index column\n",
        "item_based_df = item_based_df.drop(columns=[\"Unnamed: 0\"], errors='ignore')\n",
        "\n",
        "# Try to convert columns that are expected to be numeric\n",
        "for col in item_based_df.columns:\n",
        "    item_based_df[col] = pd.to_numeric(item_based_df[col], errors='coerce')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "item_based_df = item_based_df.select_dtypes(include=[np.number])\n",
        "\n",
        "\n",
        "filled_df = item_based_df.fillna(0)\n",
        "\n",
        "\n",
        "\n",
        "row_index = 2\n",
        "row_ratings = filled_df.iloc[row_index].values\n",
        "\n",
        "\n",
        "correlation_list = []\n",
        "\n",
        "for index in filled_df.index:\n",
        "    if index != row_index:\n",
        "        other_ratings = filled_df.iloc[index].values\n",
        "\n",
        "        if np.all(other_ratings == other_ratings[0]) or np.all(row_ratings == row_ratings[0]):\n",
        "            continue\n",
        "\n",
        "\n",
        "        try:\n",
        "            correlation, _ = pearsonr(row_ratings, other_ratings)\n",
        "            correlation_list.append({\"Pearson Correlation\": correlation, \"User\": index})\n",
        "        except ValueError:\n",
        "            continue  # Skip if there's a calculation error\n",
        "\n",
        "correlation_df = pd.DataFrame(correlation_list)\n",
        "\n",
        "\n",
        "\n",
        "top_similar_users = correlation_df.nlargest(2, \"Pearson Correlation\")\n",
        "\n",
        "null_columns = item_based_df.columns[item_based_df.iloc[row_index].isnull()]  # Get columns where the selected row has null values\n",
        "ratings_from_neighbors = item_based_df.loc[top_similar_users['User'].values, null_columns]\n",
        "\n",
        "weights = top_similar_users['Pearson Correlation'].values\n",
        "weighted_ratings = ratings_from_neighbors.T.dot(weights) / weights.sum()\n",
        "\n",
        "item_based_df.loc[row_index, null_columns] = weighted_ratings\n",
        "\n",
        "\n",
        "\n",
        "print(\"Updated DataFrame:\\n\", item_based_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aq6SAORugXc",
        "outputId": "2b485e5d-6aee-4c84-8d34-d12c7341805f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame:\n",
            "        0         1    2         3     4      5         6      7    8     9  \\\n",
            "0   2.34  2.909091  NaN       NaN   NaN    NaN       NaN    NaN  NaN   NaN   \n",
            "1   0.00  0.000000  5.0  2.444444  5.00  1.000  3.000000  3.000  5.0  2.00   \n",
            "2   5.00  5.000000  5.0  2.000000  4.00  2.000  3.888889  4.000  2.0  4.19   \n",
            "3   1.00  0.000000  3.0  1.000000  3.89  3.287  3.000000  3.489  4.0  3.00   \n",
            "4   4.13  5.000000  3.0  2.444444  0.00  5.000  5.000000  5.000  5.0  5.00   \n",
            "5   3.00  2.000000  3.0  1.000000  3.00  3.000  3.000000  1.000  5.0  3.00   \n",
            "6   0.00  1.000000  1.0  3.000000  1.00  1.000  5.000000  2.000  5.0  1.00   \n",
            "7   2.34  0.000000  5.0  2.000000  0.00  5.000  2.000000  4.000  2.0  2.00   \n",
            "8   4.00  5.000000  5.0  5.000000  5.00  3.870  5.000000  5.000  5.0  5.00   \n",
            "9   0.00  5.000000  3.8  3.000000  3.99  3.000  4.000000  2.000  3.0  4.00   \n",
            "10  2.34  5.000000  5.0  5.000000  5.00  5.000  5.000000  3.890  4.1  5.00   \n",
            "11  3.93  4.000000  3.0  0.000000  4.00  4.000  3.888889  5.000  5.0  3.00   \n",
            "\n",
            "      10        11   12  \n",
            "0    NaN       NaN  NaN  \n",
            "1   2.00  2.000000  2.0  \n",
            "2   5.00  4.000000  4.0  \n",
            "3   3.00  3.000000  3.0  \n",
            "4   0.00  3.000000  3.4  \n",
            "5   3.80  3.666667  5.0  \n",
            "6   4.09  5.000000  1.0  \n",
            "7   5.00  2.000000  5.0  \n",
            "8   5.00  5.000000  0.0  \n",
            "9   0.00  5.000000  5.0  \n",
            "10  5.00  3.666667  5.0  \n",
            "11  3.00  4.000000  4.0  \n"
          ]
        }
      ]
    }
  ]
}